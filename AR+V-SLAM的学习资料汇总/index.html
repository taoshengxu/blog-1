<!DOCTYPE html>
<html lang="en">

<!-- layout.ejs-->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="This is the site where Steven post his thoughts, ideas and feelings">
    <meta name="author" content="Huan Li">
    <meta name="keyword" content="Computer Science, Travel Notes, Ideas and Thoughts">
    <link rel="canonical" href="https://longaspire.github.io/blog/blog/AR+V-SLAM的学习资料汇总/">
    <link rel="shortcut icon" href="/blog/img/rockrms.png">
    <link rel="alternate" type="application/atom+xml" title="Little Stone" href="/atom.xml">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/animate.css/3.5.2/animate.min.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
    <link rel="stylesheet" href="https://ajax.googleapis.com/ajax/libs/jqueryui/1.12.1/themes/smoothness/jquery-ui.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jqueryui/1.12.1/jquery-ui.min.js"></script>

    <title>
        
        AR + V-SLAM的学习资料汇总｜Little Stone - Huan Li&#39;s Blog
        
    </title>

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">

    <link rel="stylesheet" href="/blog/css/main.css">

    
      <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
      <link rel="stylesheet" href="/blog/css/highlight.css">
    

    

    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>


    
      <meta name="google-site-verification" content="Q9_p57DiEwLUAkG7RSWhWgytI3usFEsDzkR3UMn-RW8" />
    

    

    


    
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


    
<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-118875263-1', 'auto');
    ga('send', 'pageview');
</script>



<script>
    var _baId = '13438f8a61802b465894989427ee4725';
    // Originial
    var _hmt = _hmt || [];
    (function() {
        var hm = document.createElement("script");
        hm.src = "//hm.baidu.com/hm.js?" + _baId;
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
    })();
</script>



    <script async defer src="https://buttons.github.io/buttons.js"></script>

<link rel="stylesheet" href="/blog/css/prism-solarizedlight.css" type="text/css">
<link rel="stylesheet" href="/blog/css/prism-line-numbers.css" type="text/css"></head>

<style>
    header.intro-header {
        background-image: url('')
    }
</style>
<!-- hack iOS CSS :active style -->
<body ontouchstart="" class="animated fadeIn">
<header>
  <nav class="navbar navbar-default header-navbar" id="nav-top" data-ispost = "true" data-istags="false" data-ishome = "false" >
    <div class="container-fluid">
      <div class="navbar-header page-scroll">
        <button type="button" class="navbar-toggle" data-toggle="collapse" aria-expanded="false"  data-target="#website_navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <span class="navbar-brand animated pulse">
          <a class="brand-logo" href="/blog/">
                <img src="/blog/img/banner.png?h=350&amp;auto=compress&amp;cs=tinysrgb" />
          </a>
        </span>
      </div>

      <div class="collapse navbar-collapse" id="website_navbar">
          <ul class="nav navbar-nav navbar-right">
              
                <li>
                  <a href="/blog/">home</a>
                </li>
              
                <li>
                  <a href="/blog/the-milestone-2018/">about</a>
                </li>
              
                <li>
                  <a href="/blog/categories/">categories</a>
                </li>
              
                <li>
                  <a href="/blog/archives/">archives</a>
                </li>
              
                <li>
                  <a href="/blog/tags/">tags</a>
                </li>
              
          </ul>
      </div>
  </nav>


  
    <style>
       .intro-header {
          background-image: url('/blog/img/firenze.png?h=350&amp;auto=compress&amp;cs=tinysrgb');
      }
    </style>

    <div class="intro-header">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1 text-center">
                    <div class="site-heading">
                        <h1>AR + V-SLAM的学习资料汇总</h1>
                        
                        

                        
                          <span class="meta">
                               <span class="meta-item">Author: Huan Li</span>
                               <span class="meta-item">Date: Oct 13, 2015</span>
                               
                                 <span class="meta-item">Updated On: May 9, 2018</span>
                               
                          </span>
                          <div class="tags text-center">
                              Categories: 
                              <a class="tag" href="/blog/categories/#科研笔记"
                                 title="科研笔记">科研笔记</a>
                              
                          </div>
                          <div class="tags text-center">
                              Tags: 
                              <a class="tag" href="/blog/tags/#Augmented Reality"
                                 title="Augmented Reality">Augmented Reality</a>
                              
                              <a class="tag" href="/blog/tags/#Kalman Filtering"
                                 title="Kalman Filtering">Kalman Filtering</a>
                              
                              <a class="tag" href="/blog/tags/#Localization"
                                 title="Localization">Localization</a>
                              
                              <a class="tag" href="/blog/tags/#SLAM"
                                 title="SLAM">SLAM</a>
                              
                          </div>
                        
                    </div>
                </div>
            </div>
        </div>
    </div>
  
</header>


<!-- Main Content -->
<!-- post.ejs -->
<article>
    <div class="container">
      <div class="col-lg-8 col-lg-offset-1 col-sm-9">
          
          <span class="post-count">3,120 words in total, 13 minutes required.</span>
          <hr>
          
          <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2 id="1-一开始"><a href="#1-一开始" class="headerlink" title="1. 一开始"></a>1. 一开始</h2><p>说到AR，现在往往要说起来SLAM (Simultaneous Localization and Mapping)，这两者之间是什么关系呢，可能会困扰很多的初学者。且先看点定义~</p>
<blockquote>
<p>Augmented reality (AR) is a technique that allows to seamlessly composite virtual objects or information into real scene.</p>
<p>  Simultaneous localization and mapping (SLAM) is a key fundamental technique for augmented reality, which provides the ability of self-localization in an unknown environment and mapping the 3D environment simultaneously. The localization and mapping enables fusion of virtual objects and real scenes in a geometrically consistent way.</p>
</blockquote>
<p><em>注意现在在AR当中多使用的是Visual SLAM，即V-SLAM的技术。</em></p>
<p>两段简短的话，直接从文献<sup id="fnref:12"><a href="#fn:12" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="基于单目视觉的同时定位与地图构建方法综述. 《计算机辅助设计与图形学学报》, 2016, 28(6):855-868.">[12]</span></a></sup>里抽出来的，实话来讲，AR里头可以借助多种多样的技术，例如</p>
<ul>
<li>采用marker (QR code / 激光栅格)，通过识别marker在图像中的位置来恢复相机三维运动，缺点是场景扩展差，要求marker始终在图像之中；</li>
<li>采用IMU (Inertial Measurement Unit)结合定位技术（如GPS和wireless技术），由于通常局部精度不够，会出现虚拟物体跳跃和偏移现象，且高精度的仪器目前还比较昂贵；</li>
<li>采用场景布置方式，在场景中布置无线信号发射，通过信号交换的方式进行自身位置的确定，多使用在机器人领域中，不适合移动端进行AR</li>
</ul>
<p>那么以上这些方法，要么受到精度和效率的影响，要么受到花费代价的影响，存在着一些局限。而SLAM，无需事先部署场景或昂贵设备，是一种markerless的方式，且能够扩展场景保证局部的定位精度，使得虚拟物体能够和现实场景进行很好的吻合，目前而言，是AR技术中最为合适的底层解决方案。</p>
<p>因此，目前而言，学习AR的算法基础，还是从SLAM和SFM (Structure From Motion)开始吧。</p>
<h2 id="2-书籍和教程"><a href="#2-书籍和教程" class="headerlink" title="2. 书籍和教程"></a>2. 书籍和教程</h2><ul>
<li><p>Multiple View Geometry in Computer Vision (Second Edition). <a href="http://www.robots.ox.ac.uk/~vgg/hzbook/" target="_blank" rel="noopener">http://www.robots.ox.ac.uk/~vgg/hzbook/</a> 这本书就是SLAM的bible了~</p>
</li>
<li><p><a href="http://www.petercorke.com/RVC/" target="_blank" rel="noopener">Robotics Vision and Control</a>. 机器视觉领域的大牛，昆士兰理工的Peter Corke写的教材</p>
</li>
<li><p><a href="http://szeliski.org/Book/" target="_blank" rel="noopener">Computer Version: Algorithms and Applications</a>. 不多说，一本CV的基础书籍，帮助理解图像和计算机视觉中的一些基础理论知识</p>
</li>
<li><p><a href="http://probabilistic-robotics.org/" target="_blank" rel="noopener">Probabilistic Robotics</a>. 没有看过，在机器视觉里是本经典教材.</p>
</li>
<li><p><a href="www.cs.unc.edu/~marc/tutorial.pdf">Visual 3D Modeling from Images</a></p>
</li>
<li><p><a href="https://ocw.mit.edu/courses/aeronautics-and-astronautics/16-412j-cognitive-robotics-spring-2005/projects/1aslam_blas_repo.pdf" target="_blank" rel="noopener">SLAM for dummies</a>， A Tutorial Approach to Simultaneous Localization and Mapping，主要还是讲EKF的东西.</p>
</li>
</ul>
<h2 id="3-经典论文和框架系统"><a href="#3-经典论文和框架系统" class="headerlink" title="3. 经典论文和框架系统"></a>3. 经典论文和框架系统</h2><h3 id="3-1-介绍SLAM算法框架的一些文献"><a href="#3-1-介绍SLAM算法框架的一些文献" class="headerlink" title="3.1 介绍SLAM算法框架的一些文献"></a>3.1 介绍SLAM算法框架的一些文献</h3><ul>
<li><p>MonoSLAM. 基于滤波器的V-SLAM 主要的参考为文献<sup id="fnref:1"><a href="#fn:1" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="Andrew J. Davison, Ian D. Reid, Nicholas Molton, Olivier Stasse. MonoSLAM: Real-Time Single Camera SLAM. IEEE Trans. Pattern Anal. Mach. Intell. 29(6): 1052-1067 (2007).">[1]</span></a></sup>，是一个基于单目摄像头的SLAM系统，MonoSLAM中每个时刻的系统状态是由当前的运动参数 $ C_t $ 和所有的三维点 $ \mathbf{X_1}, \ldots, \mathbf{X_n} $ 构成的，而当前状态的概率偏差由滤波器来控制和进行更新，选用的是扩展卡尔曼滤波器（Extended Kalman Filter，EKF），预测阶段(prediction)利用 $ C_{t-1} $ 和线性、旋转加速度和时间差对 $ C_t $进行确认，随后在更新阶段(update)则将观测到的图像点投影到三维场景中，得到新的三维点位置。注意每一时刻参与计算的系统状态只有 $ C_t $ 和所有的三维点 $ \mathbf{X_1}, \ldots, \mathbf{X_n} $ ，而不考虑 $ C_1, \ldots, C_{t-1} $ 的影响。</p>
</li>
<li><p>MSCKF. 是一个基于IMU的滤波器V-SLAM，参考文献为<sup id="fnref:2"><a href="#fn:2" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="Anastasios I. Mourikis, Stergios I. Roumeliotis. A Multi-State Constraint Kalman Filter for Vision-aided Inertial Navigation. ICRA 2007: 3565-3572.">[2]</span></a></sup>。和MonoSLAM一样，诞生于2007年，基于滤波器对系统状态进行预测更新，不同在于：预测阶段，IMU数据被用来传递系统状态；更新阶段，MSCKF是利用一个窗口大小，将临近的多帧的运动参数都加入到一个状态变量集合中。这个集合中的运动参数在不断更新的过程中不断被优化，可以用来缓解误差的累积。</p>
</li>
<li><p>PTAM. 是基于关键帧进行Bundle Adjustment的V-SLAM，07年进行了开源，其文献可见<sup id="fnref:3"><a href="#fn:3" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="Georg Klein, David W. Murray. Parallel Tracking and Mapping for Small AR Workspaces. ISMAR 2007: 225-234.">[3]</span></a></sup> <sup id="fnref:4"><a href="#fn:4" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="Georg Klein, David W. Murray. Parallel Tracking and Mapping on a camera phone. ISMAR 2009: 83-86.">[4]</span></a></sup> <sup id="fnref:5"><a href="#fn:5" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="Robert Oliver Castle, David W. Murray. Keyframe-based recognition and localization during video-rate parallel tracking and mapping. Image Vision Comput. 29(8): 524-532 (2011).">[5]</span></a></sup> <sup id="fnref:6"><a href="#fn:6" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="Georg Klein, David W. Murray. Improving the Agility of Keyframe-Based SLAM. ECCV (2) 2008: 802-815.">[6]</span></a></sup>。PTAM对于SLAM技术的发展做出的贡献源于其提出的分离tracking和mapping过程提高计算效率实现实时SLAM。在mapping的线程中仅仅维护一些稀疏关键帧(key frame)和关键帧中的可见三维点，用来进行BA (Bundle Adjustment)；在tracking的线程中可以利用后台BA出的三维结构，仅仅需要优化当前帧的运动参数即可。多说一下重定位 (re-localizing)<sup id="fnref:6"><a href="#fn:6" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="Georg Klein, David W. Murray. Improving the Agility of Keyframe-Based SLAM. ECCV (2) 2008: 802-815.">[6]</span></a></sup>的事情，即当当前帧的成功匹配点不足时，认为跟踪失败，进行重定位，需要将当前帧和已有关键帧进行比较，选择最相似的关键帧作为当前帧方位的预测；如果跟踪成功，就计算当前的运动参数是否符合关键帧的条件，若符合则传递给后台构建地图。</p>
</li>
<li><p>ORB-SLAM. 无疑的PTAM之后基于关键帧进行BA的明星算法了，2016年又有了ORB-SLAM2，其参考文献为<sup id="fnref:7"><a href="#fn:7" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="Raul Mur-Artal, J. M. M. Montiel, Juan D. Tardós. ORB-SLAM: A Versatile and Accurate Monocular SLAM System. IEEE Trans. Robotics 31(5): 1147-1163 (2015).">[7]</span></a></sup> <sup id="fnref:8"><a href="#fn:8" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="Raul Mur-Artal, Juan D. Tardós. ORB-SLAM2: an Open-Source SLAM System for Monocular, Stereo and RGB-D Cameras. CoRR abs/1610.06475 (2016).">[8]</span></a></sup>。基本上延续了PTAM的算法框架，但是其在工程方面的扩展和优化使得其成为当前最稳定可靠的单目SLAM框架。一是其选用ORB特征并基于ORB做特征匹配和重定位，在视角不变性上有一定的优势；二是加入了回路检测和闭合机制，用来消除误差累积，最后使用了方位图pose graph来完成优化实现闭合回路；三是相比PTAM对于关键帧的选择更为宽松，尽可能及时加入关键帧做BA，保证鲁棒跟踪，但是也可以删除冗余的关键帧保证BA的效率。</p>
</li>
<li><p>DTAM. 是一个基于直接跟踪法 (Direct Tracking) 的SLAM系统<sup id="fnref:9"><a href="#fn:9" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="Richard A. Newcombe, Steven Lovegrove, Andrew J. Davison. DTAM: Dense tracking and mapping in real-time. ICCV 2011: 2320-2327.">[9]</span></a></sup>，直接跟踪即不依赖于特征点的特区和匹配，而是直接通过比较像素颜色来求解相机的运动参数。DTAM是2011年提出的，特点在于能够实时恢复三维场景模型，能够保证在特征缺失、图像质量模糊的情况下依然可以稳定地直接跟踪。为了恢复三维场景，DTAM的后台程序需维护参考帧的深度图信息，其选用了逆深度方式来表达深度。</p>
</li>
<li><p>LSD-SLAM. 也是一个直接跟踪的SLAM系统<sup id="fnref:10"><a href="#fn:10" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="Jakob Engel, Thomas Schöps, Daniel Cremers. LSD-SLAM: Large-Scale Direct Monocular SLAM. ECCV (2) 2014: 834-849.">[10]</span></a></sup>。其主要相比DTAM采用了半稠密的深度图，且每个像素的深度独立计算，计算效率更高。LSD也采用关键帧表达场景，每个关键帧不仅有其图像，还有逆深度图和逆深度的方差信息。而前台采用直接跟踪的方式，恢复当前帧和关键帧的相对运动关系。后台程序通过对关键帧信息采用EKF进行更新得到优化的场景信息。同时，LSD和ORB的类似之处，在于使用了方位图pose graph的优化来取代全局优化，因此具备闭合循环回路和扩展大场景的能力。</p>
</li>
<li><p>SVO. 查看文献<sup id="fnref:15"><a href="#fn:15" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="Christian Forster, Matia Pizzoli, Davide Scaramuzza. SVO: Fast semi-direct monocular visual odometry. ICRA 2014: 15-22.">[15]</span></a></sup>，基于半稠密法的直接跟踪框架。特征跟踪采用SVO方法，对场景的要求不是特别敏感，而且效率较高，目前SVO的SLAM部分依然很难用，原因在于选择关键帧做优化，特别是地图构建方面做得还不够优。用在三维场景构建中的鲁棒性很强。</p>
</li>
</ul>
<blockquote>
<p>基本上SLAM可以分为前端的tracking和后端的mapping两大块。</p>
<ul>
<li>在tracking方面，基本上现在都采用的是图像和RGBD这两种，图像的配准分为基于稀疏(sparse)特征和稠密(dense)两种。例如MonoSLAM、MSCKF、PTAM、ORB-SLAM这些都是基于提取的特征，如FAST\ORB等等，的方法；而DTAM、LSD、SVO都是基于稠密或者半稠密进行直接跟踪的方法。</li>
<li>在后端的mapping方面，主要是将前端tracking中计算的累积误差的校正的基础上构建关键三维场景，主流有基于概率学的贝叶斯滤波器EKF\PF做优化的，还有基于稀疏的图进行优化的方法。例如MonoSLAM、MSCKF都是基于滤波进行的，PTAM和DTAM都考虑在关键帧的基础上进行BA，而LSD-SLAM和ORB-SLAM都是基于方位图进行全局优化的。</li>
</ul>
</blockquote>
<h3 id="3-2-介绍SLAM基础或关键技术的一些文献"><a href="#3-2-介绍SLAM基础或关键技术的一些文献" class="headerlink" title="3.2 介绍SLAM基础或关键技术的一些文献"></a>3.2 介绍SLAM基础或关键技术的一些文献</h3><ul>
<li><p>Graph-based SLAM，图优化方法. Davison在文献<sup id="fnref:13"><a href="#fn:13" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="Hauke Strasdat, J. M. M. Montiel, Andrew J. Davison. Visual SLAM: Why filter? Image Vision Comput. 30(2): 65-77 (2012).">[13]</span></a></sup>中介绍了图优化方法Graph-based SLAM来取代传统的EKF方法的SLAM. 相关的g2o可以查看文献<sup id="fnref:11"><a href="#fn:11" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="Rainer Kümmerle, Giorgio Grisetti, Hauke Strasdat, Kurt Konolige, Wolfram Burgard. G2o: A general framework for graph optimization. ICRA 2011: 3607-3613.">[11]</span></a></sup>.</p>
</li>
<li><p>光束平差 (Bundle Adjustment)，请看文献<sup id="fnref:14"><a href="#fn:14" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="Bill Triggs, Philip F. McLauchlan, Richard I. Hartley, Andrew W. Fitzgibbon. Bundle Adjustment - A Modern Synthesis. Workshop on Vision Algorithms 1999: 298-372.">[14]</span></a></sup>，权威的BA文献.</p>
</li>
<li><p>回路闭合 (loop closure)，参照文献<sup id="fnref:16"><a href="#fn:16" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="Raul Mur-Artal, Juan D. Tardós. Fast relocalisation and loop closing in keyframe-based SLAM. ICRA 2014: 846-853.">[16]</span></a></sup>，回路闭合检测机制可以有效的减轻在tracking过程中的误差累积导致的飘移.</p>
</li>
</ul>
<h2 id="4-在线课程和文档"><a href="#4-在线课程和文档" class="headerlink" title="4. 在线课程和文档"></a>4. 在线课程和文档</h2><ul>
<li><p>Andrew Davison. <a href="http://www.doc.ic.ac.uk/~ajd/Robotics/index.html" target="_blank" rel="noopener">http://www.doc.ic.ac.uk/~ajd/Robotics/index.html</a>. 这里还同时包含了大牛Durrant-Whyte和Tim Bailey写的<a href="http://www.doc.ic.ac.uk/~ajd/Robotics/RoboticsResources/SLAMTutorial1.pdf" target="_blank" rel="noopener">tutorial-1</a> 和 <a href="http://www.doc.ic.ac.uk/~ajd/Robotics/RoboticsResources/SLAMTutorial2.pdf" target="_blank" rel="noopener">tutorial-2</a>.</p>
</li>
<li><p>OpenCV的文档， <a href="http://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html" target="_blank" rel="noopener">Camera Calibration and 3D Reconstruction</a> 中，包含SLAM相关的基础理论公式以及C/C++/Python实现的API。</p>
</li>
<li><p>摄像头标定的教程，<a href="http://research.microsoft.com/en-us/um/people/zhang/" target="_blank" rel="noopener">MSR的张正友的主页</a>.</p>
</li>
<li><p>国内的SLAM团体，泡泡机器人发布的公开课资料. <a href="http://qoofan.com/u/MzI5MTM1MTQwMw==.html" target="_blank" rel="noopener">干货</a>.</p>
</li>
</ul>
<h2 id="5-网站"><a href="#5-网站" class="headerlink" title="5. 网站"></a>5. 网站</h2><ul>
<li><p>OpenSLAM： <a href="https://openslam.org/" target="_blank" rel="noopener">https://openslam.org/</a> ，其中包含的g2o<sup id="fnref:11"><a href="#fn:11" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="Rainer Kümmerle, Giorgio Grisetti, Hauke Strasdat, Kurt Konolige, Wolfram Burgard. G2o: A general framework for graph optimization. ICRA 2011: 3607-3613.">[11]</span></a></sup>是目前最流行的graph optimization的实现工具.</p>
</li>
<li><p>ROSROS <a href="http://www.ros.org/" target="_blank" rel="noopener">http://www.ros.org/</a> 机器视觉框架工具，跨平台，包含一整套常用的机器人理论的算法和工具的实现.</p>
</li>
<li><p>M家的 <a href="http://kastner.ucsd.edu/ryan/wp-content/uploads/sites/5/2014/03/admin/3D-reconstruction-kinect.pdf" target="_blank" rel="noopener">Kinect</a> 可看做一个RGBD Camera.</p>
</li>
<li><p>G家的 ATAP（先进技术与计划）部门开发的 <a href="https://www.google.com/atap/project-tango/" target="_blank" rel="noopener">Project Tango</a>.</p>
</li>
</ul>
<h2 id="6-一些有用的博客地址"><a href="#6-一些有用的博客地址" class="headerlink" title="6. 一些有用的博客地址"></a>6. 一些有用的博客地址</h2><ul>
<li><p><a href="http://blog.csdn.net/akunainiannian" target="_blank" rel="noopener">http://blog.csdn.net/akunainiannian</a>. 一位做机器视觉的学生的博客.</p>
</li>
<li><p><a href="http://blog.csdn.net/qinruiyan/" target="_blank" rel="noopener">http://blog.csdn.net/qinruiyan/</a>. SLAM学习笔记系列博客，讲清楚了各种估计准则在SLAM中的数学意义.</p>
</li>
<li><p><a href="https://www.zhihu.com/question/35186064" target="_blank" rel="noopener">https://www.zhihu.com/question/35186064</a>. 知乎上一个问题讨论.</p>
</li>
<li><p><a href="http://www.cnblogs.com/gaoxiang12/" target="_blank" rel="noopener">http://www.cnblogs.com/gaoxiang12/</a> THU的gaoxiang的博客.</p>
</li>
</ul>
<h2 id="7-数据集"><a href="#7-数据集" class="headerlink" title="7. 数据集"></a>7. 数据集</h2><ul>
<li><p><a href="http://www.mrpt.org/MalagaUrbanDataset" target="_blank" rel="noopener">The Málaga Stereo and Laser Urban Data Set</a>，覆盖了城市中汽车驾驶的各种情况，里面提供了双摄像头，Laser，IMU等数据以及GPS的ground truth trajectory.</p>
</li>
<li><p><a href="http://www.cvlibs.net/datasets/kitti/" target="_blank" rel="noopener">Kitti Dataset</a>，汽车驾驶数据集，包括单目视觉 双目视觉等.</p>
</li>
<li><p><a href="https://vision.in.tum.de/data/datasets/rgbd-dataset" target="_blank" rel="noopener">TU Munich Dataset</a>，里面提供了大量的室内的RGBD数据集，以及非常方便好用的benchmark tools.</p>
</li>
<li><p><a href="https://www.openslam.org/links.html" target="_blank" rel="noopener">Open SLAM Dataset</a></p>
</li>
<li><p><a href="http://3dvis.ri.cmu.edu/data-sets/localization/" target="_blank" rel="noopener">CMU Visual Localization Data Set</a>: Dataset collected using the Navlab 11 equipped with IMU, GPS, Lidars and cameras.</p>
</li>
<li><p><a href="http://www.rawseeds.org/" target="_blank" rel="noopener">The Rawseeds Project</a>: Indoor and outdoor datasets with GPS, odometry, stereo, omnicam and laser measurements for visual, laser-based, omnidirectional, sonar and multi-sensor SLAM evaluation.</p>
</li>
<li><p><a href="http://www.robots.ox.ac.uk/NewCollegeData/" target="_blank" rel="noopener">New College Dataset</a>: 30 GB of data for 6 D.O.F. navigation and mapping (metric or topological) using vision and/or laser.</p>
</li>
<li><p><a href="http://cs.nyu.edu/~silberman/datasets/" target="_blank" rel="noopener">NYU RGB-D Dataset</a>: Indoor dataset captured with a Microsoft Kinect that provides semantic labels.</p>
</li>
<li><p><a href="http://www-personal.acfr.usyd.edu.au/nebot/victoria_park.htm" target="_blank" rel="noopener">Victoria Park Sequence</a>: Widely used sequence for evaluating laser-based SLAM. Trees serve as landmarks, detection code is included.</p>
</li>
<li><p><a href="http://robots.engin.umich.edu/SoftwareData/Ford" target="_blank" rel="noopener">Ford Campus Vision and Lidar Dataset</a>: Dataset collected by a Ford F-250 pickup, equipped with IMU, Velodyne and Ladybug.</p>
</li>
</ul>
<h2 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h2><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style: none; padding-left: 0; margin-left: 40px"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">1.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Andrew J. Davison, Ian D. Reid, Nicholas Molton, Olivier Stasse. MonoSLAM: Real-Time Single Camera SLAM. IEEE Trans. Pattern Anal. Mach. Intell. 29(6): 1052-1067 (2007).<a href="#fnref:1" rev="footnote"> ↩</a></span></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">2.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Anastasios I. Mourikis, Stergios I. Roumeliotis. A Multi-State Constraint Kalman Filter for Vision-aided Inertial Navigation. ICRA 2007: 3565-3572.<a href="#fnref:2" rev="footnote"> ↩</a></span></li><li id="fn:3"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">3.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Georg Klein, David W. Murray. Parallel Tracking and Mapping for Small AR Workspaces. ISMAR 2007: 225-234.<a href="#fnref:3" rev="footnote"> ↩</a></span></li><li id="fn:4"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">4.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Georg Klein, David W. Murray. Parallel Tracking and Mapping on a camera phone. ISMAR 2009: 83-86.<a href="#fnref:4" rev="footnote"> ↩</a></span></li><li id="fn:5"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">5.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Robert Oliver Castle, David W. Murray. Keyframe-based recognition and localization during video-rate parallel tracking and mapping. Image Vision Comput. 29(8): 524-532 (2011).<a href="#fnref:5" rev="footnote"> ↩</a></span></li><li id="fn:6"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">6.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Georg Klein, David W. Murray. Improving the Agility of Keyframe-Based SLAM. ECCV (2) 2008: 802-815.<a href="#fnref:6" rev="footnote"> ↩</a></span></li><li id="fn:7"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">7.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Raul Mur-Artal, J. M. M. Montiel, Juan D. Tardós. ORB-SLAM: A Versatile and Accurate Monocular SLAM System. IEEE Trans. Robotics 31(5): 1147-1163 (2015).<a href="#fnref:7" rev="footnote"> ↩</a></span></li><li id="fn:8"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">8.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Raul Mur-Artal, Juan D. Tardós. ORB-SLAM2: an Open-Source SLAM System for Monocular, Stereo and RGB-D Cameras. CoRR abs/1610.06475 (2016).<a href="#fnref:8" rev="footnote"> ↩</a></span></li><li id="fn:9"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">9.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Richard A. Newcombe, Steven Lovegrove, Andrew J. Davison. DTAM: Dense tracking and mapping in real-time. ICCV 2011: 2320-2327.<a href="#fnref:9" rev="footnote"> ↩</a></span></li><li id="fn:10"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">10.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Jakob Engel, Thomas Schöps, Daniel Cremers. LSD-SLAM: Large-Scale Direct Monocular SLAM. ECCV (2) 2014: 834-849.<a href="#fnref:10" rev="footnote"> ↩</a></span></li><li id="fn:11"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">11.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Rainer Kümmerle, Giorgio Grisetti, Hauke Strasdat, Kurt Konolige, Wolfram Burgard. G2o: A general framework for graph optimization. ICRA 2011: 3607-3613.<a href="#fnref:11" rev="footnote"> ↩</a></span></li><li id="fn:12"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">12.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">基于单目视觉的同时定位与地图构建方法综述. 《计算机辅助设计与图形学学报》, 2016, 28(6):855-868.<a href="#fnref:12" rev="footnote"> ↩</a></span></li><li id="fn:13"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">13.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Hauke Strasdat, J. M. M. Montiel, Andrew J. Davison. Visual SLAM: Why filter? Image Vision Comput. 30(2): 65-77 (2012).<a href="#fnref:13" rev="footnote"> ↩</a></span></li><li id="fn:14"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">14.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Bill Triggs, Philip F. McLauchlan, Richard I. Hartley, Andrew W. Fitzgibbon. Bundle Adjustment - A Modern Synthesis. Workshop on Vision Algorithms 1999: 298-372.<a href="#fnref:14" rev="footnote"> ↩</a></span></li><li id="fn:15"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">15.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Christian Forster, Matia Pizzoli, Davide Scaramuzza. SVO: Fast semi-direct monocular visual odometry. ICRA 2014: 15-22.<a href="#fnref:15" rev="footnote"> ↩</a></span></li><li id="fn:16"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">16.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Raul Mur-Artal, Juan D. Tardós. Fast relocalisation and loop closing in keyframe-based SLAM. ICRA 2014: 846-853.<a href="#fnref:16" rev="footnote"> ↩</a></span></li></ol></div></div>
          
          <hr>
          <ul class="pager">
              
              <li class="previous">
                  <a href="/blog/vita/" data-toggle="tooltip" data-placement="left"
                     title="Vita: A Versatile Toolkit for Generating Indoor Mobility Data for Real-World Buildings">&larr; Previous Post</a>
              </li>
              
              
              <li class="next">
                  <a href="/blog/OpenWRT学习随录4/" data-toggle="tooltip" data-placement="top"
                     title="OpenWRT学习随录 (IV): iw">Next Post&rarr;</a>
              </li>
              
          </ul>
        
  <br>
  

  
  <!-- livere begin-->
  <div id="lv-container" data-id="city" data-uid="MTAyMC8zNjM1MC8xMjg4NQ">
      <script type="text/javascript">
          (function(d, s) {
              var j, e = d.getElementsByTagName(s)[0];

              if (typeof LivereTower === 'function') { return; }

              j = d.createElement(s);
              j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
              j.async = true;

              e.parentNode.insertBefore(j, e);
          })(document, 'script');
      </script>
      <noscript> To show LiveRe comment, please use JavaScript</noscript>
  </div>
  <!-- livere end -->
  
  </div>


        
  <div class="hidden-xs col-sm-3 toc-col">
    <div class="toc-wrap">
        Table of Contents
        
          <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-一开始"><span class="toc-text">1. 一开始</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-书籍和教程"><span class="toc-text">2. 书籍和教程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-经典论文和框架系统"><span class="toc-text">3. 经典论文和框架系统</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-介绍SLAM算法框架的一些文献"><span class="toc-text">3.1 介绍SLAM算法框架的一些文献</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-介绍SLAM基础或关键技术的一些文献"><span class="toc-text">3.2 介绍SLAM基础或关键技术的一些文献</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-在线课程和文档"><span class="toc-text">4. 在线课程和文档</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-网站"><span class="toc-text">5. 网站</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-一些有用的博客地址"><span class="toc-text">6. 一些有用的博客地址</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-数据集"><span class="toc-text">7. 数据集</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#引用"><span class="toc-text">引用</span></a></li></ol>
        
    </div>
  </div>


      </div>
  </div>
</article>

<!-- Footer -->
<!-- footer.ejs -->
<footer>
    <div class="text-center">
      <ul class="list-inline">
          
          
              <li>
                  <a target="_blank" href="https://twitter.com/LeeSte7en">
                      <span class="fa-stack fa-lg">
                          <i class="fa fa-circle fa-stack-2x"></i>
                          <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                      </span>
                  </a>
              </li>
          
          

          

          
              <li>
                  <a target="_blank" href="https://www.facebook.com/stevenhuanlee">
                      <span class="fa-stack fa-lg">
                          <i class="fa fa-circle fa-stack-2x"></i>
                          <i class="fa fa-facebook fa-stack-1x fa-inverse"></i>
                      </span>
                  </a>
              </li>
          

          
              <li>
                  <a target="_blank"  href="https://github.com/longaspire">
                      <span class="fa-stack fa-lg">
                          <i class="fa fa-circle fa-stack-2x"></i>
                          <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                      </span>
                  </a>
              </li>
          

          
              <li>
                  <a target="_blank"  href="https://www.linkedin.com/in/lihuancs">
                      <span class="fa-stack fa-lg">
                          <i class="fa fa-circle fa-stack-2x"></i>
                          <i class="fa fa-linkedin fa-stack-1x fa-inverse"></i>
                      </span>
                  </a>
              </li>
          

          
              <li>
                  <a href="mailto:lihuancs@zju.edu.cn" target="_blank">
                      <span class="fa-stack fa-lg">
                          <i class="fa fa-circle fa-stack-2x"></i>
                          <i class="fa fa-envelope fa-stack-1x fa-inverse"></i>
                      </span>
                  </a>
              </li>
          

      </ul>
     <div class="text-muted copyright">
            &copy;
            
              2018
            
            -
            Huan Li. All rights reserved.
        <br>
          
              Powered by <a target="_blank" href="https://hexo.io">Hexo</a>
          
          
          
          | Hosted by <a target="_blank" href="https://pages.github.com">GitHub Pages</a>
         <p>
             <span id="busuanzi_container_site_pv"><span id="busuanzi_value_site_pv"></span> <b>PV</b></span> -
             <span id="busuanzi_container_site_uv"><span id="busuanzi_value_site_uv"></span> <b>UV</b></span> -
             62.1k <b>Words</b>
      </div>
    </div>
</footer>

<!-- Custom Theme JavaScript -->
<script src="/blog/js/main.js"></script>

<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>

<!--fastClick.js -->
<script>
    async("//cdn.bootcss.com/fastclick/1.0.6/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>



</body>

</html>
