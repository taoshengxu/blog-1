<!DOCTYPE html>
<html lang="en">

<!-- layout.ejs-->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="This is the site where Steven post his thoughts, ideas and feelings">
    <meta name="author" content="Huan Li">
    <meta name="keyword" content="Computer Science, Travel Notes, Ideas and Thoughts">
    <link rel="canonical" href="https://longaspire.github.io/blog/blog/谈谈Metric Learning3/">
    <link rel="shortcut icon" href="/blog/img/rockrms.png">
    <link rel="alternate" type="application/atom+xml" title="Little Stone" href="/atom.xml">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/animate.css/3.5.2/animate.min.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
    <link rel="stylesheet" href="https://ajax.googleapis.com/ajax/libs/jqueryui/1.12.1/themes/smoothness/jquery-ui.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jqueryui/1.12.1/jquery-ui.min.js"></script>

    <title>
        
        谈谈Metric Learning（III）-- ITML｜Little Stone - Huan Li&#39;s Blog
        
    </title>

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">

    <link rel="stylesheet" href="/blog/css/main.css">

    
      <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
      <link rel="stylesheet" href="/blog/css/highlight.css">
    

    

    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>


    
      <meta name="google-site-verification" content="Q9_p57DiEwLUAkG7RSWhWgytI3usFEsDzkR3UMn-RW8" />
    

    

    


    
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


    
<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-118875263-1', 'auto');
    ga('send', 'pageview');
</script>





    <script async defer src="https://buttons.github.io/buttons.js"></script>

</head>

<style>
    header.intro-header {
        background-image: url('')
    }
</style>
<!-- hack iOS CSS :active style -->
<body ontouchstart="" class="animated fadeIn">
<header>
  <nav class="navbar navbar-default header-navbar" id="nav-top" data-ispost = "true" data-istags="false" data-ishome = "false" >
    <div class="container-fluid">
      <div class="navbar-header page-scroll">
        <button type="button" class="navbar-toggle" data-toggle="collapse" aria-expanded="false"  data-target="#website_navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <span class="navbar-brand animated pulse">
          <a class="brand-logo" href="/blog/">
                <img src="/blog/img/banner.png?h=350&amp;auto=compress&amp;cs=tinysrgb" />
          </a>
        </span>
      </div>

      <div class="collapse navbar-collapse" id="website_navbar">
          <ul class="nav navbar-nav navbar-right">
              
                <li>
                  <a href="/blog/">home</a>
                </li>
              
                <li>
                  <a href="/blog/the-milestone-2018/">about</a>
                </li>
              
                <li>
                  <a href="/blog/categories/">categories</a>
                </li>
              
                <li>
                  <a href="/blog/archives/">archives</a>
                </li>
              
                <li>
                  <a href="/blog/tags/">tags</a>
                </li>
              
          </ul>
      </div>
  </nav>


  
    <style>
       .intro-header {
          background-image: url('/blog/img/firenze.png?h=350&amp;auto=compress&amp;cs=tinysrgb');
      }
    </style>

    <div class="intro-header">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1 text-center">
                    <div class="site-heading">
                        <h1>谈谈Metric Learning（III）-- ITML</h1>
                        
                        
                          <span class="meta">
                               <span class="meta-item">Author: Huan Li</span>
                               <span class="meta-item">Date: Jun 3, 2015</span>
                               
                                 <span class="meta-item">Updated On: May 8, 2018</span>
                               
                          </span>
                          <div class="tags text-center">
                              Categories: 
                              <a class="tag" href="/blog/categories/#Machine Learning"
                                 title="Machine Learning">Machine Learning</a>
                              
                              <a class="tag" href="/blog/categories/#Research"
                                 title="Research">Research</a>
                              
                          </div>
                          <div class="tags text-center">
                              Tags: 
                              <a class="tag" href="/blog/tags/#similarity measurement"
                                 title="similarity measurement">similarity measurement</a>
                              
                              <a class="tag" href="/blog/tags/#ITML"
                                 title="ITML">ITML</a>
                              
                              <a class="tag" href="/blog/tags/#metric learning"
                                 title="metric learning">metric learning</a>
                              
                              <a class="tag" href="/blog/tags/#Information Theoretic"
                                 title="Information Theoretic">Information Theoretic</a>
                              
                              <a class="tag" href="/blog/tags/#KL Divergence"
                                 title="KL Divergence">KL Divergence</a>
                              
                              <a class="tag" href="/blog/tags/#LogDet"
                                 title="LogDet">LogDet</a>
                              
                          </div>
                        
                    </div>
                </div>
            </div>
        </div>
    </div>
  
</header>


<!-- Main Content -->
<!-- post.ejs -->
<article>
    <div class="container">
      <div class="col-lg-8 col-lg-offset-1 col-sm-9">
          
          
          <h3 id="1-引言"><a href="#1-引言" class="headerlink" title="1.引言"></a>1.引言</h3><p>这一篇我们来谈谈Metric Learning中，更具体而言，是Mahalanobis Distance Learning中的经典算法ITML，也称作<strong>_Information-Theoretic Metric Learning_</strong>，顾名思义，就是借助信息学理论知识对Mahalanobis distance进行优化。<a href="https://scholar.google.com/scholar?hl=zh-CN&amp;q=information+theoretic+metric+learning+&amp;btnG=&amp;lr=" target="_blank" rel="noopener">这篇文章</a>发表在2007年机器学习会议ICML上，随后取得了巨大成功，后来的工作很多都得到了作者Jason Davis对于LogDet divergence在metric learning中使用的启发，进行了一系列理论和实验优化。</p>
<h3 id="2-问题定义"><a href="#2-问题定义" class="headerlink" title="2.问题定义"></a>2.问题定义</h3><h4 id="2-1-距离"><a href="#2-1-距离" class="headerlink" title="2.1 距离"></a>2.1 距离</h4><p>对于一个n个点构成的集合[latex]{x_1,…,x_n}[/latex], 其中[latex]x_i \in \mathbb{R}^d[/latex]，我们可以得到马氏距离的定义：</p>
<blockquote>
<p>[latex]d_A(x_i, x_j) = (x_i - x_j)^T A (x_i - x_j)[/latex]</p>
</blockquote>
<p>这里我们稍微采取了一点处理，首先为了避免平方根，我们将马氏距离取平方；其次，我们用一个symmetric PSD矩阵$latex A $来替代之前使用的$latex M $。</p>
<h4 id="2-2-限制集合-Constraints-Set"><a href="#2-2-限制集合-Constraints-Set" class="headerlink" title="2.2 限制集合 Constraints Set"></a>2.2 限制集合 Constraints Set</h4><p>之前我们将集合中的items分为must-link和must-not-link集合，对应的是一个similar set [latex]\mathit{S}[/latex]和一个dissimilar set [latex]\mathit{D}[/latex]。</p>
<p>这里，我们将其称之为Interpoint Distance Constraints，其中对于两个相似（不相似）的items 有</p>
<blockquote>
<p>$latex d_A(x_i,x_j) \leq u $<br>  $latex d_A(x_i,x_j) \geq l $</p>
</blockquote>
<p>$latex u $($latex l $)是一个值很小(大)的upper（lower） bound。</p>
<h4 id="2-3-问题核心"><a href="#2-3-问题核心" class="headerlink" title="2.3 问题核心"></a>2.3 问题核心</h4><p>除了这些side information，对于一个半监督或者全监督问题，我们往往会获取到一些关于使用怎么的度量更容易得到好的accuracy的指导，这些知识我们称之为先验的 (prior)。</p>
<p>例如，对于一个数据是Gaussian分布的问题，我们往往期望<code>parameterizing the distance function by the inverse of the sample covariance</code>。</p>
<p>同样，对于一些欧式空间的距离度量，我们往往希望distance function是接近欧式距离的，因此，我们需要对我们的PSD matrix 也就是$latex A $采取优化，具体而言就是，当我的先验知识告诉我$latex A $应该要逼近一个由[latex]A_0[/latex]定义的度量时，我们往往需要在满足限制条件的情况下，使得$latex A $尽可能地接近我们pick up的[latex]A_0[/latex]。</p>
<p>这儿，就是ITML的核心思想，如何去选择合适的[latex]A_0[/latex]并使得我们learn的$latex A $尽可能逼近它。</p>
<h4 id="2-4-使用KL散度"><a href="#2-4-使用KL散度" class="headerlink" title="2.4 使用KL散度"></a>2.4 使用KL散度</h4><p>又一次使用散度的概念，这在我们Metric Learning系列的<a href="http://blog.longaspire.com/archives/347" target="_blank" rel="noopener">第一篇</a>已经提到，散度用于分析随机变量在两个分布下的相似度。这里的两个分布自然是由[latex]A_0[/latex]和$latex A $来度量的，这是因为[latex]A_0[/latex]和$latex A $是两个分布的协方差矩阵的逆。</p>
<p>我们需要来定义一个，$latex x_i $在$latex A $下的Gaussian Distribution</p>
<blockquote>
<p>[latex]p(x;A) = \frac{1}{Z} \cdot \exp(-\frac{1}{2} d_A(x,\nu))[/latex]</p>
</blockquote>
<p>其中，$latex Z $是一个用于正规化处理的常数，而$latex A $是分布的协方差covariance，[latex]\nu[/latex]是mean，那么我们可以定义出 [latex] A [/latex]与 [latex] A_0 [/latex] 这两个分布的KL散度</p>
<blockquote>
<p>[latex] \mathit{KL}(p(x; A_0) || p(x; A)) = \int p(x ; A_0) \log{\frac{p(x; A_0)}{p(x; A)}} dx[/latex]</p>
</blockquote>
<h4 id="2-5-问题形式化"><a href="#2-5-问题形式化" class="headerlink" title="2.5 问题形式化"></a>2.5 问题形式化</h4><p>那么，对于给定的constraints set [latex]\mathit{S}[/latex] 和 [latex]\mathit{D}[/latex]，我们将问题形式化为：</p>
<blockquote>
<p>$latex \min\limits_{A} \mathit{KL} (p(x; A_0) || p(x; A)) $<br>  $latex <del>~$<br>  $latex \text{s.t.}$<br>  $latex d_A(x_i, x_j) \leq u  ~</del>(i,j) \in \mathit{S} $<br>  $latex d_A(x_i, x_j) \geq l  ~~~(i,j) \in \mathit{D} $</p>
</blockquote>
<h3 id="3-算法"><a href="#3-算法" class="headerlink" title="3. 算法"></a>3. 算法</h3><h4 id="3-1-LogDet优化"><a href="#3-1-LogDet优化" class="headerlink" title="3.1 LogDet优化"></a>3.1 LogDet优化</h4><p>先看一个凸函数</p>
<blockquote>
<p>[latex]\Phi(X) = - \log {det} X[/latex]</p>
</blockquote>
<p>这个函数是定义在正定矩阵的cone上的，基于这个函数，我们可以把它的<a href="http://en.wikipedia.org/wiki/Bregman_divergence" target="_blank" rel="noopener">Bregman matrix divergence</a>做成一个LogDet divergence。事实上，LogDet divergence是用于来描述两个矩阵的差异性</p>
<p>上述divergence，我们提到是对于两个矩阵，即$latex A $和[latex]A_0[/latex]的差异性的度量，可以这么写：</p>
<blockquote>
<p>[latex]D_{ld}(A,A_0) = tr(A A^{-1}) - \log {det} (A A_0^{-1}) - n[/latex]</p>
</blockquote>
<p>联系我们在上一节中介绍过的KL散度，两个Metric定义中的矩阵[latex]A[/latex]和[latex]A_0[/latex]的“closeness”就可以通过散度，也就是LogDet divergence来一起定义，那么写成</p>
<blockquote>
<p>[latex] \mathit{KL} (p(x;A_0)||p(x;A)) = \frac{1}{2} \cdot D_{ld}(A_0^{-1},A^{-1}) = \frac{1}{2} \cdot D_{ld}(A,A_0)[/latex]</p>
</blockquote>
<p>事实上，这个等价推导过程是非常巧妙的，它借鉴了微分相对熵的一些知识，这在<a href="http://machinelearning.wustl.edu/mlpapers/paper_files/NIPS2006_147.pdf" target="_blank" rel="noopener">Davis2006</a>中有很详细的介绍。</p>
<p>最后，在这里我们可知，1.5给出的问题形式化，从minimize KL divergence最后变成了一个minimize LogDet的问题。但是，我们给出更加严格化的问题描述:</p>
<ol>
<li>给出[latex]c(i,j)[/latex]，表示第(i,j)-th个constraint</li>
<li>给出trade-off parameter [latex]\gamma[/latex]</li>
<li>给出松弛变量slack variables，并将其初始化为[latex]\vec{\xi}_0[/latex]，注意这是一个vector，其中等于[latex] u [/latex]的部分为similar constraints，等于[latex] l [/latex]的部分为dissimilar constraints</li>
<li>那么对于一个Mahalonbios距离的学习问题，我们需要保证[latex]A[/latex]是对称半正定的，形式化就可以写成[latex]A \succeq 0[/latex]，现在我们要最小化A和[latex]\vec{\xi}[/latex]，并保证两个矩阵相似。</li>
</ol>
<p>终于，我们可以来重新定义一个严格的问题描述：</p>
<blockquote>
<p>[latex]\min\limits_{A \succeq 0, \vec{\xi}} D_{ld}(A,A_0) + \gamma \cdot D_{ld}(diag(\vec{\xi}), diag(\vec{\xi_0}))[/latex]<br>  $latex <del>~$<br>  $latex \text{s.t.}$<br>  $latex tr(A(x_i,x_j)(x_i,x_j)^T) \leq \vec{\xi}_{c(i,j)} ~</del> (i,j) \in \mathit{S} $<br>  $latex tr(A(x_i,x_j)(x_i,x_j)^T) \geq \vec{\xi}_{c(i,j)} ~~~ (i,j) \in \mathit{D} $</p>
</blockquote>
<p>那么最终，ITML的距离度量，从一堆constraints中对于A的优化实际上变成了一个LogDet的优化问题。</p>
<p>这个函数，我们可以概括为：</p>
<ol>
<li>希望$latex A $ 和 [latex]A_0[/latex]尽量靠近</li>
<li>希望对应的松弛变量$latex \vec{\xi} $ 和 $latex \vec{\xi}_0 $ 尽可能地靠近</li>
<li>优化参数$latex A $为半正定</li>
</ol>
<h4 id="3-2-算法解释"><a href="#3-2-算法解释" class="headerlink" title="3.2 算法解释"></a>3.2 算法解释</h4><p>我们先把算法的伪代码贴出看看</p>
<pre lang="c" line="1">

Input:  X: input d*n matrix; 
        S: set of similar pairs;
        D: set of dissimilar pairs;
        u,l: distance thresholds;
        A_0: input Mahalanobis matrix;
        r: slack parameter;
        c: constraint index mapping

Output: A: output Mahalanobis matrix

//initialization
A = A_0;
forall i,j: 
   lambda_ij = 0; 
forall i,j:
   idx = c(i,j);
   if (i,j) is in S:
     xi_idx = u;
   else:
     xi_idx = l;

//iteration
while(!convergence):
   pick a constraint (i,j); idx = c(i,j);
   p = dot(dot((x_i - x_j).T, A), (x_i - x_j));
   if (i,j) is in S:
      delta = 1;
   else:
      delta = -1;
   alpha = min(lambda_ij, 1/2*(1/p - r/xi_idx));
   beta = delta * alpha / (1 - delta * alpha * p);
   xi_idx = r * xi_idx / (r + delta * alpha * xi_idx);
   lambda_ij = lambda_ij - alpha;
   A = A + beta * dot(dot(dot(A, (x_i - x_j)), (x_i - x_j).T), A)))

return A

</pre>

<p>我们可以看到，上述是一个projected gradient descent的过程。循环中的35行实际上是一次projection，保证A依然在convex set中，这事实上是一个Bregman projection过程：</p>
<blockquote>
<p>[latex]A_{t+1} = A_{t} + \beta A_{t}(x_i, x_j)(x_i, x_j)^TA_{t}[/latex]</p>
</blockquote>
<p>其中，[latex]\beta[/latex]是projection parameter，一个与constraint相关的拉格朗日乘子。一次projection的时间复杂度是[latex]O(d^2)[/latex]，那么对于有c个constraint的一次iteration，则时间复杂度为[latex]O(cd^2)[/latex]。</p>
<p>————————-分割线————————-</p>
<p>写到这里，也许你已经大概清楚了ITML在做什么，简单的实现是怎样的。然而，我们还没有完全谈到ITML的精髓，后续我们会介绍引入kernel learning的方法来解决参数优化的问题，希望有更多篇幅来分享这一算法。</p>

          
          <hr>
          <ul class="pager">
              
              <li class="previous">
                  <a href="/blog/谈谈Metric Learning4/" data-toggle="tooltip" data-placement="left"
                     title="谈谈Metric Learning(IV) - ITML进阶">&larr; Previous Post</a>
              </li>
              
              
              <li class="next">
                  <a href="/blog/谈谈Metric Learning2/" data-toggle="tooltip" data-placement="top"
                     title="谈谈Metric Learning(II)">Next Post&rarr;</a>
              </li>
              
          </ul>
        
  <br>
  

  
  <!-- livere begin-->
  <div id="lv-container" data-id="city" data-uid="MTAyMC8zNjM1MC8xMjg4NQ">
      <script type="text/javascript">
          (function(d, s) {
              var j, e = d.getElementsByTagName(s)[0];

              if (typeof LivereTower === 'function') { return; }

              j = d.createElement(s);
              j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
              j.async = true;

              e.parentNode.insertBefore(j, e);
          })(document, 'script');
      </script>
      <noscript> To show LiveRe comment, please use JavaScript</noscript>
  </div>
  <!-- livere end -->
  
  </div>


        
  <div class="hidden-xs col-sm-3 toc-col">
    <div class="toc-wrap">
        Table of Contents
        
          <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-引言"><span class="toc-number">1.</span> <span class="toc-text">1.引言</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-问题定义"><span class="toc-number">2.</span> <span class="toc-text">2.问题定义</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-距离"><span class="toc-number">2.1.</span> <span class="toc-text">2.1 距离</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-限制集合-Constraints-Set"><span class="toc-number">2.2.</span> <span class="toc-text">2.2 限制集合 Constraints Set</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-问题核心"><span class="toc-number">2.3.</span> <span class="toc-text">2.3 问题核心</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-4-使用KL散度"><span class="toc-number">2.4.</span> <span class="toc-text">2.4 使用KL散度</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-5-问题形式化"><span class="toc-number">2.5.</span> <span class="toc-text">2.5 问题形式化</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-算法"><span class="toc-number">3.</span> <span class="toc-text">3. 算法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-LogDet优化"><span class="toc-number">3.1.</span> <span class="toc-text">3.1 LogDet优化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-算法解释"><span class="toc-number">3.2.</span> <span class="toc-text">3.2 算法解释</span></a></li></ol></li></ol>
        
    </div>
  </div>


      </div>
  </div>
</article>

<!-- Footer -->
<!-- footer.ejs -->
<footer>
    <div class="text-center">
      <ul class="list-inline">
          
          
              <li>
                  <a target="_blank" href="https://twitter.com/LeeSte7en">
                      <span class="fa-stack fa-lg">
                          <i class="fa fa-circle fa-stack-2x"></i>
                          <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                      </span>
                  </a>
              </li>
          
          

          

          
              <li>
                  <a target="_blank" href="https://www.facebook.com/stevenhuanlee">
                      <span class="fa-stack fa-lg">
                          <i class="fa fa-circle fa-stack-2x"></i>
                          <i class="fa fa-facebook fa-stack-1x fa-inverse"></i>
                      </span>
                  </a>
              </li>
          

          
              <li>
                  <a target="_blank"  href="https://github.com/longaspire">
                      <span class="fa-stack fa-lg">
                          <i class="fa fa-circle fa-stack-2x"></i>
                          <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                      </span>
                  </a>
              </li>
          

          
              <li>
                  <a target="_blank"  href="https://www.linkedin.com/in/lihuancs">
                      <span class="fa-stack fa-lg">
                          <i class="fa fa-circle fa-stack-2x"></i>
                          <i class="fa fa-linkedin fa-stack-1x fa-inverse"></i>
                      </span>
                  </a>
              </li>
          

          
              <li>
                  <a href="mailto:lihuancs@zju.edu.cn" target="_blank">
                      <span class="fa-stack fa-lg">
                          <i class="fa fa-circle fa-stack-2x"></i>
                          <i class="fa fa-envelope fa-stack-1x fa-inverse"></i>
                      </span>
                  </a>
              </li>
          

      </ul>
     <div class="text-muted copyright">
            &copy;
            
              2018
            
            -
            Huan Li. All rights reserved.
        <br>
          
              Powered by <a target="_blank" href="https://hexo.io">Hexo</a>
          
          
          
          | Hosted by <a target="_blank" href="https://pages.github.com">GitHub Pages</a>
         <p>
            <span id="busuanzi_container_site_pv"><span id="busuanzi_value_site_pv"></span> PV</span> -
            <span id="busuanzi_container_site_uv"><span id="busuanzi_value_site_uv"></span> UV
        </span>
      </div>
    </div>
</footer>

<!-- Custom Theme JavaScript -->
<script src="/blog/js/main.js"></script>

<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>

<!--fastClick.js -->
<script>
    async("//cdn.bootcss.com/fastclick/1.0.6/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>



</body>

</html>
